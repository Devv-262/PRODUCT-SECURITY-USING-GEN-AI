import json
import yaml
import os
import subprocess
import datetime
import chromadb
from pathlib import Path
from typing import Dict, List, Any
import requests
from sentence_transformers import SentenceTransformer
import re

class VulnerabilityRAGPipeline:
    def __init__(self,
                 chromadb_path: str = "./chroma_db",
                 local_llm_endpoint: str = "http://localhost:11434/api/generate",
                 local_llm_model: str = "llama3:8b",
                 prompt_file: str = "./prompt.txt"):
        """
        Initialize the RAG pipeline for vulnerability analysis and remediation
        """
        self.chromadb_path = chromadb_path
        self.local_llm_endpoint = local_llm_endpoint
        self.local_llm_model = local_llm_model
        self.prompt_file = prompt_file
        self.output_dir = Path("./vulnerability_reports")
        self.output_dir.mkdir(exist_ok=True)
        
        # Initialize ChromaDB
        self.chroma_client = chromadb.PersistentClient(path=chromadb_path)
        self.collection = self.chroma_client.get_or_create_collection(
            name="vulnerability_analysis",
            metadata={"description": "Container vulnerability analysis data"}
        )
        
        # Initialize embedding model
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')

    def load_prompt_template(self) -> str:
        """
        Load the comprehensive prompt from external file
        """
        try:
            with open(self.prompt_file, 'r', encoding='utf-8') as f:
                return f.read()
        except FileNotFoundError:
            print(f"Prompt file {self.prompt_file} not found. Using default prompt.")
            return self.get_default_prompt()
        except Exception as e:
            print(f"Error loading prompt file: {e}")
            return self.get_default_prompt()

    def get_default_prompt(self) -> str:
        """
        Fallback default prompt if external file is not available
        """
        return """You are a Senior DevSecOps Engineer. Analyze vulnerability scan results and provide specific remediation steps while preserving the original container image structure and functionality. Generate appropriate fixes for the detected vulnerabilities."""

    def read_original_files(self) -> Dict[str, str]:
        """
        Read original project files for context (generic approach for all image types)
        """
        files_content = {}
        
        # Read original Dockerfile if exists
        dockerfile_paths = ["Dockerfile", "./Dockerfile", "../Dockerfile"]
        for path in dockerfile_paths:
            if os.path.exists(path):
                with open(path, 'r', encoding='utf-8') as f:
                    files_content["dockerfile"] = f.read()
                break
        
        # Look for common dependency files
        dependency_files = {
            "requirements.txt": ["requirements.txt", "./requirements.txt", "../requirements.txt"],
            "package.json": ["package.json", "./package.json", "../package.json"],
            "pom.xml": ["pom.xml", "./pom.xml", "../pom.xml"],
            "go.mod": ["go.mod", "./go.mod", "../go.mod"],
            "Gemfile": ["Gemfile", "./Gemfile", "../Gemfile"],
            "composer.json": ["composer.json", "./composer.json", "../composer.json"],
            "Cargo.toml": ["Cargo.toml", "./Cargo.toml", "../Cargo.toml"]
        }
        
        for file_type, paths in dependency_files.items():
            for path in paths:
                if os.path.exists(path):
                    with open(path, 'r', encoding='utf-8') as f:
                        files_content[file_type] = f.read()
                    break
        
        # Look for common application files
        app_files = {
            "app.py": ["app.py", "./app.py", "../app.py"],
            "main.py": ["main.py", "./main.py", "../main.py"],
            "index.js": ["index.js", "./index.js", "../index.js"],
            "server.js": ["server.js", "./server.js", "../server.js"],
            "app.js": ["app.js", "./app.js", "../app.js"],
            "main.java": ["main.java", "./main.java", "../main.java"],
            "main.go": ["main.go", "./main.go", "../main.go"]
        }
        
        for file_type, paths in app_files.items():
            for path in paths:
                if os.path.exists(path):
                    with open(path, 'r', encoding='utf-8') as f:
                        files_content[file_type] = f.read()
                    break
        
        return files_content

    def extract_vulnerabilities_with_fixes(self, json_file: str) -> List[Dict]:
        """
        Extract only HIGH and CRITICAL vulnerabilities that have available fixes
        """
        with open(json_file, 'r', encoding='utf-8') as f:
            trivy_data = json.load(f)
        
        fixable_vulns = []
        
        if trivy_data.get("Results"):
            for result in trivy_data["Results"]:
                if result.get("Vulnerabilities"):
                    for vuln in result["Vulnerabilities"]:
                        severity = vuln.get("Severity", "").upper()
                        if severity in ["HIGH", "CRITICAL"]:
                            # Check if fix version is available
                            fixed_version = vuln.get("FixedVersion", "")
                            if fixed_version and fixed_version != "":
                                fixable_vulns.append({
                                    "cve_id": vuln.get("VulnerabilityID", ""),
                                    "package": vuln.get("PkgName", ""),
                                    "current_version": vuln.get("InstalledVersion", ""),
                                    "fixed_version": fixed_version,
                                    "severity": severity,
                                    "cvss_score": vuln.get("CVSS", {}).get("nvd", {}).get("V3Score", 0),
                                    "title": vuln.get("Title", ""),
                                    "description": vuln.get("Description", "")[:200] + "..." if vuln.get("Description", "") else ""
                                })
        
        return fixable_vulns

    def extract_original_image_info(self, image_name: str) -> Dict:
        """
        Extract information about the original image for better context (generic approach)
        """
        try:
            # Try to inspect the image to get more context
            result = subprocess.run([
                "docker", "inspect", image_name
            ], capture_output=True, text=True, check=True)
            
            inspect_data = json.loads(result.stdout)[0]
            
            image_info = {
                "exposed_ports": list(inspect_data.get("Config", {}).get("ExposedPorts", {}).keys()),
                "env_vars": inspect_data.get("Config", {}).get("Env", []),
                "cmd": inspect_data.get("Config", {}).get("Cmd", []),
                "entrypoint": inspect_data.get("Config", {}).get("Entrypoint", []),
                "working_dir": inspect_data.get("Config", {}).get("WorkingDir", ""),
                "user": inspect_data.get("Config", {}).get("User", ""),
                "base_image": inspect_data.get("Config", {}).get("Image", ""),
                "architecture": inspect_data.get("Architecture", ""),
                "os": inspect_data.get("Os", "")
            }
            
            return image_info
            
        except Exception as e:
            print(f"Could not inspect image {image_name}: {e}")
            return {
                "exposed_ports": [],
                "env_vars": [],
                "cmd": [],
                "entrypoint": [],
                "working_dir": "",
                "user": "",
                "base_image": "",
                "architecture": "amd64",
                "os": "linux"
            }

    def run_trivy_scan(self, image_name: str) -> Dict[str, str]:
        """
        Execute Trivy scan with NVD and OSV integration
        """
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_image_name = image_name.replace(":", "_").replace("/", "_")
        
        # File paths for outputs
        txt_output = self.output_dir / f"trivy_scan_{safe_image_name}_{timestamp}.txt"
        json_output = self.output_dir / f"trivy_scan_{safe_image_name}_{timestamp}.json"
        sbom_output = self.output_dir / f"trivy_sbom_{safe_image_name}_{timestamp}.json"
        
        try:
            # Run Trivy vulnerability scan (table format for readability)
            subprocess.run([
                "trivy", "image", 
                "--format", "table",
                "--output", str(txt_output),
                "--severity", "HIGH,CRITICAL",
                image_name
            ], check=True)
            
            # Run Trivy vulnerability scan (JSON format for processing)
            subprocess.run([
                "trivy", "image",
                "--format", "json",
                "--output", str(json_output),
                "--severity", "HIGH,CRITICAL",
                image_name
            ], check=True)
            
            # Generate SBOM
            subprocess.run([
                "trivy", "image",
                "--format", "cyclonedx",
                "--output", str(sbom_output),
                image_name
            ], check=True)
            
            print(f"Trivy scan completed for {image_name}")
            return {
                "txt_file": str(txt_output),
                "json_file": str(json_output),
                "sbom_file": str(sbom_output),
                "image_name": image_name,
                "timestamp": timestamp
            }
            
        except subprocess.CalledProcessError as e:
            print(f"Trivy scan failed: {e}")
            raise

    def create_image_metadata(self, image_name: str, scan_results: Dict) -> Dict:
        """
        Create image metadata in the specified YAML format (generic for all image types)
        """
        with open(scan_results["json_file"], 'r', encoding='utf-8') as f:
            trivy_data = json.load(f)
        
        # Get image info for better metadata
        image_info = self.extract_original_image_info(image_name)
        
        # Determine default port based on common patterns
        default_port = 8080  # Generic default
        if image_info["exposed_ports"]:
            first_port = image_info["exposed_ports"][0]
            try:
                default_port = int(first_port.split("/")[0])
            except:
                default_port = 8080
        
        # Extract metadata from Trivy results
        metadata = {
            "name": image_name.split("/")[-1].split(":")[0],
            "type": "container",
            "description": f"Container image: {image_name}",
            "image_info": {
                "base_image": image_info.get("base_image", ""),
                "architecture": image_info.get("architecture", "amd64"),
                "os": image_info.get("os", "linux"),
                "exposed_ports": image_info.get("exposed_ports", []),
                "working_dir": image_info.get("working_dir", ""),
                "user": image_info.get("user", "")
            },
            "internalinterface": {
                "ingress": [{
                    "name": "ContainerIngress",
                    "purpose": "Application traffic ingress",
                    "applicationlayer": {
                        "protocol": "HTTP",
                        "traffic": "bi-directional"
                    },
                    "transportlayer": {
                        "protocol": "TCP",
                        "port": default_port,
                        "remoteport": "ANY"
                    }
                }],
                "egress": [{
                    "name": "ContainerEgress", 
                    "purpose": "Outbound traffic",
                    "applicationlayer": {
                        "protocol": "HTTP"
                    },
                    "transportlayer": {
                        "protocol": "TCP",
                        "port": "ANY",
                        "remoteport": 443
                    }
                }]
            },
            "externalinterface": {
                "ingress": [{
                    "name": "ExternalIngress",
                    "purpose": "External HTTP access",
                    "applicationlayer": {
                        "protocol": "HTTP"
                    },
                    "transportlayer": {
                        "protocol": "TCP",
                        "port": default_port,
                        "remoteport": "ANY"
                    },
                    "networklayer": {
                        "protocol": "IPv4"
                    }
                }],
                "egress": [{
                    "name": "ExternalEgress",
                    "purpose": "External API calls",
                    "applicationlayer": {
                        "protocol": "HTTPS"
                    },
                    "transportlayer": {
                        "protocol": "TCP", 
                        "port": "ANY",
                        "remoteport": 443
                    },
                    "networklayer": {
                        "protocol": "IPv4"
                    }
                }]
            },
            "securitycontext": {
                "protocol": "TLS1.2",
                "comment": "HTTPS used for secure communications",
                "authentication": {
                    "peer": {
                        "credentials": [{
                            "type": "X.509-certificate",
                            "stored-format": "k8s-secret",
                            "stored-location": "k8s-etcd"
                        }]
                    }
                }
            },
            "containers": [],
            "scan_metadata": {
                "scan_time": scan_results["timestamp"],
                "trivy_version": "latest",
                "total_vulnerabilities": len(trivy_data.get("Results", [{}])[0].get("Vulnerabilities", [])) if trivy_data.get("Results") else 0
            }
        }
        
        # Save metadata as YAML
        metadata_file = self.output_dir / f"metadata_{scan_results['timestamp']}.yaml"
        with open(metadata_file, 'w') as f:
            yaml.dump(metadata, f, default_flow_style=False)
        
        return metadata

    def chunk_sbom_data(self, sbom_file: str, chunk_size: int = 1000) -> List[Dict]:
        """
        Divide SBOM into manageable chunks for LLM processing
        """
        with open(sbom_file, 'r', encoding='utf-8') as f:
            sbom_data = json.load(f)
        
        chunks = []
        
        # Chunk components
        if "components" in sbom_data:
            components = sbom_data["components"]
            for i in range(0, len(components), chunk_size):
                chunk = {
                    "type": "components",
                    "data": components[i:i + chunk_size],
                    "chunk_id": f"components_{i//chunk_size + 1}",
                    "total_chunks": (len(components) + chunk_size - 1) // chunk_size
                }
                chunks.append(chunk)
        
        # Chunk vulnerabilities if present
        if "vulnerabilities" in sbom_data:
            vulns = sbom_data["vulnerabilities"]
            for i in range(0, len(vulns), chunk_size):
                chunk = {
                    "type": "vulnerabilities",
                    "data": vulns[i:i + chunk_size],
                    "chunk_id": f"vulnerabilities_{i//chunk_size + 1}",
                    "total_chunks": (len(vulns) + chunk_size - 1) // chunk_size
                }
                chunks.append(chunk)
        
        return chunks

    def store_in_chromadb(self, scan_results: Dict, metadata: Dict, sbom_chunks: List[Dict]):
        """
        Store all vulnerability data in ChromaDB vector database
        """
        # Read text report with UTF-8 encoding
        with open(scan_results["txt_file"], 'r', encoding='utf-8', errors='ignore') as f:
            txt_content = f.read()
        
        # Read JSON report with UTF-8 encoding
        with open(scan_results["json_file"], 'r', encoding='utf-8') as f:
            json_content = json.load(f)
        
        documents = []
        metadatas = []
        ids = []
        
        # Store text report
        documents.append(txt_content)
        metadatas.append({
            "type": "trivy_text_report",
            "image_name": scan_results["image_name"],
            "timestamp": scan_results["timestamp"],
            "file_path": scan_results["txt_file"]
        })
        ids.append(f"txt_report_{scan_results['timestamp']}")
        
        # Store JSON report summary
        json_summary = f"Trivy JSON Report for {scan_results['image_name']}\n"
        if json_content.get("Results"):
            for result in json_content["Results"]:
                if result.get("Vulnerabilities"):
                    json_summary += f"Target: {result.get('Target', 'Unknown')}\n"
                    json_summary += f"Vulnerabilities found: {len(result['Vulnerabilities'])}\n"
                    for vuln in result["Vulnerabilities"][:10]:  # First 10 for summary
                        json_summary += f"- {vuln.get('VulnerabilityID', 'N/A')}: {vuln.get('Severity', 'N/A')} - {vuln.get('Title', 'N/A')}\n"
        
        documents.append(json_summary)
        metadatas.append({
            "type": "trivy_json_summary",
            "image_name": scan_results["image_name"],
            "timestamp": scan_results["timestamp"],
            "file_path": scan_results["json_file"]
        })
        ids.append(f"json_report_{scan_results['timestamp']}")
        
        # Store metadata
        metadata_text = yaml.dump(metadata)
        documents.append(metadata_text)
        metadatas.append({
            "type": "image_metadata",
            "image_name": scan_results["image_name"],
            "timestamp": scan_results["timestamp"]
        })
        ids.append(f"metadata_{scan_results['timestamp']}")
        
        # Store SBOM chunks
        for i, chunk in enumerate(sbom_chunks):
            chunk_text = json.dumps(chunk, indent=2)
            documents.append(chunk_text)
            metadatas.append({
                "type": f"sbom_chunk_{chunk['type']}",
                "chunk_id": chunk["chunk_id"],
                "image_name": scan_results["image_name"],
                "timestamp": scan_results["timestamp"]
            })
            ids.append(f"sbom_chunk_{i}_{scan_results['timestamp']}")
        
        # Add to ChromaDB
        self.collection.add(
            documents=documents,
            metadatas=metadatas,
            ids=ids
        )
        
        print(f"Stored {len(documents)} documents in ChromaDB")

    def generate_enhanced_prompt(self, image_name: str, original_files: Dict, fixable_vulns: List[Dict], image_info: Dict) -> str:
        """
        Generate enhanced prompt with original files and vulnerability context (generic for all image types)
        """
        prompt_template = self.load_prompt_template()
        
        # Build vulnerability context
        vuln_context = "IDENTIFIED FIXABLE VULNERABILITIES:\n\n"
        for vuln in fixable_vulns:
            vuln_context += f"- {vuln['cve_id']}: {vuln['package']} {vuln['current_version']} -> {vuln['fixed_version']} ({vuln['severity']})\n"
        
        # Build original files context
        files_context = "\nORIGINAL PROJECT FILES:\n\n"
        
        if "dockerfile" in original_files:
            files_context += f"=== ORIGINAL DOCKERFILE ===\n{original_files['dockerfile']}\n\n"
        
        # Add all found dependency files
        dependency_extensions = ['.txt', '.json', '.xml', '.mod', 'file', '.toml']
        for file_type, content in original_files.items():
            if file_type != "dockerfile" and any(ext in file_type.lower() for ext in dependency_extensions):
                files_context += f"=== ORIGINAL {file_type.upper()} ===\n{content}\n\n"
        
        # Add application files
        app_extensions = ['.py', '.js', '.java', '.go', '.rb', '.php']
        for file_type, content in original_files.items():
            if any(ext in file_type.lower() for ext in app_extensions):
                files_context += f"=== APPLICATION CODE ({file_type}) ===\n{content}\n\n"
        
        # Build image-specific preservation context
        exposed_ports = image_info.get("exposed_ports", [])
        working_dir = image_info.get("working_dir", "/app")
        user = image_info.get("user", "")
        cmd = image_info.get("cmd", [])
        entrypoint = image_info.get("entrypoint", [])
        
        preservation_context = f"""
MANDATORY PRESERVATION REQUIREMENTS FOR {image_name}:
- Image architecture: {image_info.get('architecture', 'amd64')}
- Operating system: {image_info.get('os', 'linux')}
- Exposed ports: {exposed_ports} (DO NOT CHANGE)
- Working directory: {working_dir} (DO NOT CHANGE unless necessary)
- User: {user if user else 'Default user'} (PRESERVE if set)
- Command: {cmd if cmd else 'Default command'} (PRESERVE functionality)
- Entrypoint: {entrypoint if entrypoint else 'Default entrypoint'} (PRESERVE if set)
- Application compatibility: MUST be maintained

VULNERABILITY FIXING STRATEGY:
- Update ONLY the packages listed in the fixable vulnerabilities
- Maintain compatibility with existing application dependencies
- Use appropriate version constraints for the technology stack
- Test compatibility with provided application code
- Preserve all functional aspects of the original container
"""
        
        full_prompt = f"{prompt_template}\n\n{vuln_context}\n{files_context}\n{preservation_context}"
        return full_prompt

    def query_local_llm(self, prompt: str, context: str, max_retries: int = 2) -> str:
        """
        Query local LLM model via API with retry logic
        """
        original_context = context
        
        for attempt in range(max_retries + 1):
            try:
                if attempt > 0:
                    max_context_length = 4000 // (attempt + 1)
                    context = original_context[:max_context_length] + "\n[Context truncated for processing]"
                    print(f"Retry {attempt}: Using reduced context ({len(context)} chars)")
                
                full_prompt = f"{context}\n\n{prompt}"
                
                payload = {
                    "model": self.local_llm_model,
                    "prompt": full_prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.1,
                        "top_p": 0.9,
                        "max_tokens": 3000,
                        "timeout": 600
                    }
                }
                
                print(f"Querying local LLM (attempt {attempt + 1})...")
                response = requests.post(self.local_llm_endpoint, json=payload, timeout=900)
                response.raise_for_status()
                return response.json()["response"]
                
            except requests.exceptions.Timeout:
                print(f"Timeout on attempt {attempt + 1}")
                if attempt == max_retries:
                    return "Error: Local LLM processing timed out after multiple attempts."
            except Exception as e:
                print(f"Error on attempt {attempt + 1}: {e}")
                if attempt == max_retries:
                    return f"Error: Could not get response from local LLM after {max_retries + 1} attempts - {e}"
        
        return "Error: All retry attempts failed."

    def retrieve_context_from_chromadb(self, query: str, n_results: int = 3) -> str:
        """
        Retrieve relevant context from ChromaDB for the query
        """
        try:
            results = self.collection.query(
                query_texts=[query],
                n_results=n_results
            )
            
            context = "RELEVANT VULNERABILITY DATA:\n\n"
            for i, (doc, metadata) in enumerate(zip(results["documents"][0], results["metadatas"][0])):
                context += f"--- Document {i+1} ({metadata.get('type', 'unknown')}) ---\n"
                doc_content = doc[:1500] + "..." if len(doc) > 1500 else doc
                context += doc_content + "\n\n"
            
            return context
        except Exception as e:
            print(f"Error retrieving context: {e}")
            return "No context available due to retrieval error."

    def extract_fixes_from_response(self, llm_response: str, timestamp: str, original_files: Dict) -> Dict[str, str]:
        """
        Extract Dockerfile and dependency files from LLM response and save them (generic approach)
        """
        files_generated = {}
        
        # Extract Dockerfile
        dockerfile_patterns = [
            r'```dockerfile\s*(.*?)```',
            r'```Dockerfile\s*(.*?)```',
            r'```\s*#.*?FROM.*?\n(.*?)```'
        ]
        
        for pattern in dockerfile_patterns:
            dockerfile_match = re.search(pattern, llm_response, re.DOTALL | re.IGNORECASE)
            if dockerfile_match:
                dockerfile_content = dockerfile_match.group(1)
                dockerfile_path = self.output_dir / f"fixed_dockerfile_{timestamp}"
                with open(dockerfile_path, 'w', encoding='utf-8') as f:
                    f.write(dockerfile_content)
                files_generated["dockerfile"] = str(dockerfile_path)
                print(f"Fixed Dockerfile saved to {dockerfile_path}")
                break
        
        # Extract dependency files based on what was originally present
        dependency_patterns = {
            "requirements.txt": [r'```\s*requirements\.txt\s*(.*?)```', r'```txt\s*((?:.*?==.*?\n)+)```'],
            "package.json": [r'```json\s*(\{.*?"dependencies".*?\})```'],
            "pom.xml": [r'```xml\s*(<\?xml.*?</project>)```'],
            "go.mod": [r'```\s*go\.mod\s*(.*?)```', r'```mod\s*(.*?)```'],
            "Gemfile": [r'```ruby\s*(gem\s+.*?)```', r'```\s*Gemfile\s*(.*?)```'],
            "composer.json": [r'```json\s*(\{.*?"require".*?\})```'],
            "Cargo.toml": [r'```toml\s*(\[dependencies\].*?)```']
        }
        
        for file_type, patterns in dependency_patterns.items():
            if file_type in original_files:  # Only extract if original existed
                for pattern in patterns:
                    match = re.search(pattern, llm_response, re.DOTALL | re.IGNORECASE)
                    if match:
                        content = match.group(1)
                        file_path = self.output_dir / f"fixed_{file_type.replace('.', '_')}_{timestamp}"
                        if file_type.endswith('.txt'):
                            file_path = self.output_dir / f"fixed_{file_type}_{timestamp}"
                        with open(file_path, 'w', encoding='utf-8') as f:
                            f.write(content)
                        files_generated[file_type] = str(file_path)
                        print(f"Fixed {file_type} saved to {file_path}")
                        break
        
        return files_generated
    

#pod security starts



    def scan_yaml_with_kubescore(self, yaml_file: str) -> str:
        """
        Scan the given YAML manifest file with kube-score and return the report as text.
        """
        try:
            result = subprocess.run(
                ["kube-score", "score", yaml_file],
                capture_output=True, text=True, check=True
            )
            print(f"kube-score scan completed for {yaml_file}")
            return result.stdout
        except subprocess.CalledProcessError as e:
            print(f"kube-score scan failed: {e}")
            return e.output if hasattr(e, 'output') else str(e)

    def scan_yaml_with_kubescape(self, yaml_file: str) -> str:
        """
        Scan the given YAML manifest file with kubescape and return the report as text.
        """
        try:
            result = subprocess.run(
                ["kubescape", "scan", yaml_file],
                capture_output=True, text=True, check=True
            )
            print(f"kubescape scan completed for {yaml_file}")
            return result.stdout
        except subprocess.CalledProcessError as e:
            print(f"kubescape scan failed: {e}")
            return e.output if hasattr(e, 'output') else str(e)

    def load_pod_security_prompt(self, prompt_file: str = "./prompt_pod_security.txt") -> str:
        """
        Load enhanced pod security prompt from file or return default
        """
        try:
            with open(prompt_file, 'r', encoding='utf-8') as f:
                return f.read()
        except FileNotFoundError:
            print(f"Pod security prompt file {prompt_file} not found. Using default.")
            return self.get_default_pod_security_prompt()
        except Exception as e:
            print(f"Error loading pod security prompt: {e}")
            return self.get_default_pod_security_prompt()

    def get_default_pod_security_prompt(self) -> str:
        """
        Enhanced default pod security prompt for Kubernetes manifest analysis
        """
        return """You are a Senior Kubernetes Security Engineer and DevSecOps specialist with expertise in container orchestration security, RBAC, network policies, and cloud-native security best practices.

MISSION: Analyze the provided Kubernetes YAML manifests and their security scan reports from kube-score and kubescape. Generate comprehensive remediation recommendations to significantly reduce the security risk score and improve compliance posture.

ANALYSIS FRAMEWORK:

1. **Vulnerability Assessment:**
   - Identify all HIGH and CRITICAL security violations
   - Map each finding to specific YAML configuration issues
   - Calculate risk impact based on external exposure and privilege levels
   - Prioritize fixes based on CVSS scores and exploitability

2. **Configuration Analysis:**
   - Pod Security Standards compliance (Privileged, Baseline, Restricted)
   - Security Context misconfigurations (runAsRoot, capabilities, etc.)
   - Resource limits and requests (prevent resource exhaustion attacks)
   - Network exposure and isolation gaps
   - RBAC over-permissioning and privilege escalation risks

3. **Remediation Strategy:**
   - Provide specific YAML field changes with exact values
   - Explain security improvement and risk reduction for each fix
   - Maintain application functionality while enhancing security
   - Follow principle of least privilege and defense in depth

OUTPUT REQUIREMENTS:

## 1. Executive Security Summary
- Total security violations found (by severity)
- Current vs target security score
- Primary attack vectors identified
- Estimated risk reduction percentage

## 2. Critical Findings Table
| Severity | Finding | Current Config | Security Risk | CVSS Impact |
|----------|---------|----------------|---------------|-------------|
| HIGH | Container runs as root | runAsUser: 0 | Privilege escalation | 8.5 |

## 3. Detailed Remediation Plan

For each critical finding:
**Finding:** [Description]
**Current Configuration:** [Problematic YAML]
**Security Risk:** [Specific threat and attack scenario]
**Recommended Fix:** [Exact YAML changes]
**Security Improvement:** [How this reduces risk]

## 4. Updated Secure YAML Manifests
Provide complete, corrected YAML files with:
- Proper security contexts (runAsNonRoot, readOnlyRootFilesystem)
- Resource limits and requests
- Network policies with minimal required access
- RBAC with least privilege principles
- Pod Security Standards compliance

## 5. Security Validation Commands
- Commands to verify security improvements
- Testing procedures for functionality validation
- Monitoring recommendations for ongoing security

## 6. Compliance and Best Practices
- CIS Kubernetes Benchmark alignment
- NSA/CISA hardening guide compliance
- Industry-specific security requirements

CRITICAL SECURITY PRINCIPLES:
- Never run containers as root (UID 0)
- Always set resource limits to prevent DoS
- Use read-only root filesystems when possible
- Implement network segmentation with NetworkPolicies
- Apply least privilege RBAC permissions
- Enable security monitoring and audit logging

Focus on actionable, specific fixes that directly address scan findings while maintaining application functionality. Explain the security rationale for every recommendation."""

    def generate_pod_security_remediation_report(self, yaml_files: list, pod_security_prompt: str = "./prompt_pod_security.txt") -> dict:
        """
        Scan YAML manifests with kube-score and kubescape, then use LLM to generate comprehensive remediation report
        """
        print("Starting Kubernetes pod security analysis...")
        
        # Scan each YAML file
        reports = {}
        total_issues = 0
        
        for yaml_path in yaml_files:
            print(f"Scanning {yaml_path}...")
            
            # Read YAML content
            with open(yaml_path, 'r', encoding='utf-8') as f:
                yaml_content = f.read()
            
            # Run security scans
            kube_score_report = self.scan_yaml_with_kubescore(yaml_path)
            kubescape_report = self.scan_yaml_with_kubescape(yaml_path)
            
            # Count issues for summary
            score_issues = kube_score_report.count("CRITICAL") + kube_score_report.count("WARNING")
            total_issues += score_issues
            
            reports[yaml_path] = {
                "yaml_content": yaml_content,
                "kube_score_report": kube_score_report,
                "kubescape_report": kubescape_report,
                "issues_found": score_issues
            }
        
        # Combine all reports for LLM analysis
        combined_report_text = f"KUBERNETES SECURITY SCAN SUMMARY:\nTotal files scanned: {len(yaml_files)}\nTotal security issues found: {total_issues}\n\n"
        
        for fname, data in reports.items():
            combined_report_text += (
                f"\n{'='*60}\n"
                f"YAML FILE: {fname}\n"
                f"{'='*60}\n"
                f"MANIFEST CONTENT:\n"
                f"{data['yaml_content']}\n\n"
                f"KUBE-SCORE SECURITY REPORT:\n"
                f"{data['kube_score_report']}\n\n"
                f"KUBESCAPE SECURITY REPORT:\n"
                f"{data['kubescape_report']}\n\n"
            )
        
        # Load enhanced pod security prompt
        prompt_text = self.load_pod_security_prompt(pod_security_prompt)
        
        # Generate LLM remediation analysis
        print("Analyzing pod security with local LLM for comprehensive remediation...")
        llm_response = self.query_local_llm(prompt_text, combined_report_text)
        
        # Save comprehensive remediation report
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = self.output_dir / f"pod_security_remediation_report_{timestamp}.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(f"# Kubernetes Pod Security Remediation Report\n\n")
            f.write(f"**Generated:** {timestamp}\n")
            f.write(f"**Files Analyzed:** {len(yaml_files)}\n")
            f.write(f"**Security Issues Found:** {total_issues}\n\n")
            f.write(f"## Analyzed Files\n")
            for fname in yaml_files:
                f.write(f"- {fname} ({reports[fname]['issues_found']} issues)\n")
            f.write(f"\n## Security Analysis & Remediation\n\n")
            f.write(llm_response)
        
        print(f"Pod Security remediation report saved to {report_file}")
        
        return {
            "pod_security_report_file": str(report_file),
            "llm_analysis": llm_response,
            "timestamp": timestamp,
            "files_analyzed": len(yaml_files),
            "total_issues": total_issues
        }

    def generate_remediation_report(self, image_name: str, scan_results: Dict) -> Dict:
        """
        Generate comprehensive vulnerability remediation report (generic for all image types)
        """
        print("Reading original project files...")
        original_files = self.read_original_files()
        
        print("Extracting fixable vulnerabilities...")
        fixable_vulns = self.extract_vulnerabilities_with_fixes(scan_results["json_file"])
        
        print("Getting image information...")
        image_info = self.extract_original_image_info(image_name)
        
        # Retrieve context from ChromaDB
        context = self.retrieve_context_from_chromadb(
            f"vulnerabilities HIGH CRITICAL {image_name} remediation fixes"
        )
        
        # Generate enhanced prompt
        prompt = self.generate_enhanced_prompt(image_name, original_files, fixable_vulns, image_info)
        
        # Query local LLM
        print("Analyzing vulnerabilities with local LLM...")
        response = self.query_local_llm(prompt, context)
        
        # Save full response
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = self.output_dir / f"remediation_report_{timestamp}.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(f"# Vulnerability Remediation Report\n\n")
            f.write(f"**Image:** {image_name}\n")
            f.write(f"**Generated:** {timestamp}\n")
            f.write(f"**Fixable Vulnerabilities:** {len(fixable_vulns)}\n\n")
            f.write(f"## Image Information\n\n")
            f.write(f"- Architecture: {image_info.get('architecture', 'Unknown')}\n")
            f.write(f"- OS: {image_info.get('os', 'Unknown')}\n")
            f.write(f"- Exposed Ports: {image_info.get('exposed_ports', [])}\n")
            f.write(f"- Working Directory: {image_info.get('working_dir', 'Unknown')}\n")
            f.write(f"- User: {image_info.get('user', 'Default')}\n\n")
            f.write(f"## Fixable Vulnerabilities Summary\n\n")
            for vuln in fixable_vulns:
                f.write(f"- **{vuln['cve_id']}**: {vuln['package']} {vuln['current_version']} -> {vuln['fixed_version']} ({vuln['severity']})\n")
            f.write(f"\n## Remediation Analysis\n\n")
            f.write(response)
        
        # Extract and save fixes
        generated_files = self.extract_fixes_from_response(response, timestamp, original_files)
        
        print(f"Remediation report saved to {report_file}")
        
        return {
            "report_file": str(report_file),
            "analysis": response,
            "fixable_vulnerabilities": len(fixable_vulns),
            "generated_files": generated_files,
            "timestamp": timestamp,
            "image_info": image_info
        }

    def run_pipeline(self, image_name: str) -> Dict:
        """
        Execute the complete RAG vulnerability remediation pipeline (generic for all images)
        """
        print(f"Starting RAG Vulnerability Pipeline for: {image_name}")
        
        # Step 1: Run Trivy scan
        print("Running Trivy vulnerability scan...")
        scan_results = self.run_trivy_scan(image_name)
        
        # Step 2: Create image metadata
        print("Creating image metadata...")
        metadata = self.create_image_metadata(image_name, scan_results)
        
        # Step 3: Chunk SBOM data
        print("Processing SBOM data...")
        sbom_chunks = self.chunk_sbom_data(scan_results["sbom_file"])
        
        # Step 4: Store in ChromaDB
        print("Storing data in ChromaDB...")
        self.store_in_chromadb(scan_results, metadata, sbom_chunks)
        
        # Step 5: Generate remediation report with files
        print("Generating intelligent remediation report with fixed files...")
        remediation_report = self.generate_remediation_report(image_name, scan_results)
        
        print(f"Pipeline completed successfully!")
        print(f"All outputs saved in: {self.output_dir}")
        
        if "dockerfile" in remediation_report["generated_files"]:
            print(f"Fixed Dockerfile: {remediation_report['generated_files']['dockerfile']}")
        
        # Print info about other generated files
        for file_type, file_path in remediation_report["generated_files"].items():
            if file_type != "dockerfile":
                print(f"Fixed {file_type}: {file_path}")
        
        return {
            "scan_results": scan_results,
            "metadata": metadata,
            "sbom_chunks": len(sbom_chunks),
            "remediation_report": remediation_report,
            "output_directory": str(self.output_dir)
        }

# ---------------------------
# MAIN EXECUTION
# ---------------------------

if __name__ == "__main__":
    # Initialize pipeline with configurable LLM model
    pipeline = VulnerabilityRAGPipeline(
        local_llm_model="llama3:8b" 
    )
    
    # Image vulnerability scanning (generic functionality)
    image_name = input("Enter Docker image name to analyze (or press Enter to skip): ").strip()
    if image_name:
        print(f"\nRunning image vulnerability analysis...")
        results = pipeline.run_pipeline(image_name)
        print(f"\nImage analysis complete! Check {results['output_directory']} for results.")
        
        # Display image scan summary
        remediation = results["remediation_report"]
        print(f"\nIMAGE SCAN SUMMARY:")
        print(f"- Image: {image_name}")
        print(f"- Architecture: {remediation['image_info'].get('architecture', 'Unknown')}")
        print(f"- OS: {remediation['image_info'].get('os', 'Unknown')}")
        print(f"- Fixable vulnerabilities: {remediation['fixable_vulnerabilities']}")
        print(f"- Report: {remediation['report_file']}")
        if remediation["generated_files"]:
            print(f"- Generated files: {list(remediation['generated_files'].keys())}")
    
    # Kubernetes YAML security scanning (unchanged functionality)
    print(f"\nChecking for Kubernetes manifest files...")
    yaml_files = []
    possible_files = [
        "deployment.yaml", "service.yaml", "networkpolicy.yaml", 
        "rbac.yaml", "configmap.yaml", "secret.yaml", "ingress.yaml",
        "k8s-deployment.yaml", "k8s-service.yaml", "kubernetes.yaml"
    ]
    
    for f in possible_files:
        if os.path.exists(f):
            yaml_files.append(f)
    
    if yaml_files:
        print(f"Found {len(yaml_files)} Kubernetes manifest files:")
        for f in yaml_files:
            print(f"  - {f}")
        
        proceed = input("\nRun pod security analysis on these files? (y/n): ").strip().lower()
        if proceed in ['y', 'yes']:
            print(f"\nRunning Kubernetes pod security analysis...")
            
            # Create enhanced pod security prompt if it doesn't exist
            pod_prompt_file = "./prompt_pod_security.txt"
            if not os.path.exists(pod_prompt_file):
                print(f"Creating enhanced pod security prompt at {pod_prompt_file}")
                with open(pod_prompt_file, 'w', encoding='utf-8') as f:
                    f.write(pipeline.get_default_pod_security_prompt())
            
            pod_sec_result = pipeline.generate_pod_security_remediation_report(
                yaml_files, pod_security_prompt=pod_prompt_file
            )
            
            print(f"\nPod security analysis complete!")
            print(f"\nPOD SECURITY SUMMARY:")
            print(f"- Files analyzed: {pod_sec_result['files_analyzed']}")
            print(f"- Security issues found: {pod_sec_result['total_issues']}")
            print(f"- Remediation report: {pod_sec_result['pod_security_report_file']}")
        else:
            print("Skipping pod security analysis.")
    else:
        print("No Kubernetes manifest files found in current directory.")
        print("   Place your deployment.yaml, service.yaml, etc. files here to enable pod security scanning.")
    
    print(f"\nAll analysis complete! Check the vulnerability_reports/ directory for detailed reports.")